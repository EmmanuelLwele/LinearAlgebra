{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nEigendecomposition can also be used to calculate the principal components of a matrix in the\\nPrincipal Component Analysis method or PCA that can be used to reduce the dimensionality\\nof data in machine learning.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# eye-gan\n",
    "'''Matrix decompositions are a useful tool for reducing a matrix to their constituent parts in\n",
    "order to simplify a range of more complex operations. '''\n",
    "# Perhaps the most used type of matrix\n",
    "# decomposition is the eigendecomposition that decomposes a matrix into eigenvectors and\n",
    "# eigenvalues.\n",
    "\n",
    "#  A · v = λ · v\n",
    "# A is the parent square matrix that we are\n",
    "# decomposing, v is the eigenvector of the matrix, and λ is the lowercase Greek letter lambda and\n",
    "# represents the eigenvalue scalar.\n",
    "\n",
    "'''The parent matrix can be shown\n",
    "to be a product of the eigenvectors and eigenvalues.\n",
    "A = Q · Λ · Q^T'''\n",
    "'''\n",
    "Eigendecomposition can also be used to calculate the principal components of a matrix in the\n",
    "Principal Component Analysis method or PCA that can be used to reduce the dimensionality\n",
    "of data in machine learning.'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[ 1.61168440e+01 -1.11684397e+00 -1.30367773e-15] \n",
      "\n",
      "[[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]]\n"
     ]
    }
   ],
   "source": [
    "# 15.4 Calculation of Eigendecomposition\n",
    "from numpy import array\n",
    "from numpy.linalg import eig\n",
    "\n",
    "# define matrix\n",
    "A = array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "print(A)\n",
    "\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "print(values,'\\n')\n",
    "print(vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.61168440e+01 -1.11684397e+00 -1.30367773e-15]\n",
      "[[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]] \n",
      "\n",
      "[ -3.73863537  -8.46653421 -13.19443305]\n",
      "[ -3.73863537  -8.46653421 -13.19443305]\n"
     ]
    }
   ],
   "source": [
    "# 15.5 Confirm an Eigenvector and Eigenvalue\n",
    "from numpy import array\n",
    "from numpy.linalg import eig\n",
    "\n",
    "# define matrix\n",
    "A = array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "print(values)\n",
    "print(vectors, '\\n')\n",
    "\n",
    "# confirm first eigenvector\n",
    "B = A.dot(vectors[:,0])\n",
    "print(B)\n",
    "C = vectors[:, 0] * values[0]\n",
    "print(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2 3]\n",
      " [4 5 6]\n",
      " [7 8 9]]\n",
      "[ 1.61168440e+01 -1.11684397e+00 -1.30367773e-15]\n",
      "[[-0.23197069 -0.78583024  0.40824829]\n",
      " [-0.52532209 -0.08675134 -0.81649658]\n",
      " [-0.8186735   0.61232756  0.40824829]]\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]\n",
      " [7. 8. 9.]]\n"
     ]
    }
   ],
   "source": [
    "# 15.6 Reconstruct Matrix\n",
    "'''The eigenvalues need to be arranged into a diagonal matrix. The NumPy\n",
    "diag() function can be used for this. Next, we need to calculate the inverse of the eigenvector\n",
    "matrix, which we can achieve with the inv() NumPy function. Finally, these elements need to\n",
    "be multiplied together with the dot() function.'''\n",
    "\n",
    "# reconstrunct matrix\n",
    "from numpy import diag\n",
    "from numpy.linalg import inv\n",
    "from numpy.linalg import eig\n",
    "from numpy import array\n",
    "\n",
    "# define matrix\n",
    "A = array([\n",
    "    [1,2,3],\n",
    "    [4,5,6],\n",
    "    [7,8,9]\n",
    "])\n",
    "print(A)\n",
    "\n",
    "# factorize\n",
    "values, vectors = eig(A)\n",
    "print(values)\n",
    "print(vectors)\n",
    "\n",
    "# create matrix from eigenvectors\n",
    "Q = vectors\n",
    "\n",
    "# create inv eigenvector matrix\n",
    "R = inv(Q)\n",
    "\n",
    "# create diagonal matrix from eigen values\n",
    "L = diag(values)\n",
    "\n",
    "# reconstruct the original matrix\n",
    "B = Q.dot(L).dot(R)\n",
    "print(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''15.7 Extensions\n",
    "This section lists some ideas for extending the tutorial that you may wish to explore.\n",
    " Develop an eigendecomposition and reconstruction of your own small contrived array data.\n",
    " List ten high-level operations that make use of the eigendecomposition.\n",
    " Implement the eigendecomposition operation from scratch for matrices defined as lists of\n",
    "lists.'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
